<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Abdullah Alghamdi - ASL Research</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #f5f5f5;
      margin: 0;
      padding: 20px;
    }

    .profile-container {
      max-width: 700px;
      margin: 0 auto;
      background: white;
      padding: 30px;
      border-radius: 15px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
      text-align: center;
    }

    .profile-container img {
      width: 200px;
      height: auto;
      border-radius: 10px;
      border: 3px solid #004080;
    }

    .caption {
      font-size: 18px;
      margin-top: 15px;
      font-weight: bold;
      color: #004080;
    }

    .description {
      margin-top: 20px;
      text-align: justify;
      font-size: 16px;
      color: #333;
      line-height: 1.6;
    }
  </style>
</head>
<body>
  <div class="profile-container">
    <img src="CB15C521-83F5-4DEB-8133-4CB2102506F3.png" alt="Abdullah Alghamdi">
    <div class="caption">Hello, I am Abdullah Alghamdi</div>
    <div class="description">
      This is what I research for ASL data: Sign Language Detection Using Human Pose Estimation. The paper “Real-Time Sign Language Detection Using Human Pose Estimation” by Amit Moryossef and team explores detecting whether someone is signing in real time—not recognizing signs, just detecting activity. It's important for making video calls more accessible for Deaf users by showing their video when they sign.<br><br>
      They used the Public DGS Corpus with OpenPose tracking and neural networks (LSTM). The system is fast and accurate, even on standard CPUs. However, it still has limitations—like recognizing only one signer at a time and needing diverse training data.<br><br>
      This research is a big step for improving digital accessibility and helps with efforts like Gallaudet’s ASL video tracking projects.
    </div>
  </div>
</body>
</html>